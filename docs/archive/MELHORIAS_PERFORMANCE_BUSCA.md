# Melhorias para An√°lise e Busca de Melhor Performance

**Data:** 24 de dezembro de 2025  
**Framework Version:** 7.2  
**Objetivo:** Otimizar a busca de hiperpar√¢metros e melhorar an√°lise de performance


---


## üéØ Melhorias Dispon√≠veis

### 1. Otimiza√ß√£o Bayesiana Avan√ßada (J√° Implementado)

O framework j√° usa **Tree-structured Parzen Estimator (TPE)** da biblioteca Optuna, que √© estado-da-arte em otimiza√ß√£o Bayesiana.

**Configura√ß√£o Atual:**

```python
sampler = TPESampler(
    seed=42,
    n_startup_trials=10  # Trials aleat√≥rios iniciais para explora√ß√£o
)
pruner = MedianPruner(
    n_startup_trials=5,
    n_warmup_steps=3  # Interrompe trials ruins ap√≥s 3 √©pocas
)

```text

**Melhorias Poss√≠veis:**


#### 1.1. Aumentar Trials Iniciais de Explora√ß√£o

```bash

# Modificar no c√≥digo (linha 3959):
n_startup_trials=20  # Mais explora√ß√£o inicial (padr√£o: 10)

```text

**Benef√≠cio:** Melhor cobertura do espa√ßo de hiperpar√¢metros antes de focar em regi√µes promissoras.


#### 1.2. Ajustar Estrat√©gia de Pruning

```bash

# Modificar no c√≥digo (linha 3960):
n_warmup_steps=5  # Aguardar mais √©pocas antes de podar (padr√£o: 3)

```text

**Benef√≠cio:** Evita descartar configura√ß√µes que come√ßam mal mas melhoram depois.


---


### 2. Usar Samplers Alternativos

#### 2.1. CMA-ES Sampler (Melhor para Espa√ßos Cont√≠nuos)

```python
from optuna.samplers import CmaEsSampler

sampler = CmaEsSampler(
    seed=42,
    sigma0=0.1  # Desvio padr√£o inicial
)

```text

**Quando usar:** Ideal quando os hiperpar√¢metros s√£o principalmente cont√≠nuos (learning rate, noise level).


#### Vantagens:
- ‚úÖ Melhor para otimiza√ß√£o de par√¢metros cont√≠nuos
- ‚úÖ Converg√™ncia mais r√°pida em espa√ßos suaves
- ‚úÖ Robusto a ru√≠do


#### 2.2. NSGAII Sampler (Multi-Objetivo)

```python
from optuna.samplers import NSGAIISampler

sampler = NSGAIISampler(
    population_size=50,
    mutation_prob=0.1,
    crossover_prob=0.9
)

```text

**Quando usar:** Otimizar m√∫ltiplos objetivos simultaneamente (e.g., acur√°cia + tempo de treinamento).


**Exemplo de uso:**

```python
def objective_multi(trial):

    # ... configurar VQC ...
    accuracy = vqc.score(X_test, y_test)
    training_time = vqc.tempo_treinamento
    
    # Retornar m√∫ltiplos objetivos
    return accuracy, -training_time  # Maximizar acur√°cia, minimizar tempo

```text

---


### 3. Hyperband Pruning (Mais Agressivo)

```python
from optuna.pruners import HyperbandPruner

pruner = HyperbandPruner(
    min_resource=1,        # M√≠nimo de √©pocas
    max_resource=20,       # M√°ximo de √©pocas
    reduction_factor=3     # Fator de redu√ß√£o
)

```text

**Benef√≠cio:** Descarta configura√ß√µes ruins muito mais r√°pido, economizando tempo computacional.


---


### 4. An√°lise de Import√¢ncia Aprimorada

#### 4.1. Import√¢ncia via fANOVA (J√° Implementado)

```python
importances = optuna.importance.get_param_importances(
    study,
    evaluator=optuna.importance.FanovaImportanceEvaluator()
)

```text

#### 4.2. Adicionar Import√¢ncia via Permuta√ß√£o

```python
from optuna.importance import MeanDecreaseImpurityImportanceEvaluator

importances_mdi = optuna.importance.get_param_importances(
    study,
    evaluator=MeanDecreaseImpurityImportanceEvaluator()
)

```text

**Benef√≠cio:** M√∫ltiplas m√©tricas de import√¢ncia para valida√ß√£o cruzada.


---


### 5. Busca em Duas Fases (Recomendado)

**Fase 1: Explora√ß√£o Global (Bayesian)**

```bash

# 1. Encontrar regi√£o promissora (1-2 horas)
export VQC_BAYESIAN=1
export VQC_QUICK=1
python framework_investigativo_completo.py --bayes --trials 200 --dataset-bayes all

```text

**Fase 2: Refinamento Local (Grid Search Focado)**

```python

# 2. Grid search refinado na regi√£o √≥tima encontrada
# Modificar ranges baseado nos melhores trials:

# Se melhor foi: depolarizante, nivel=0.001, strongly_entangling, quantico
# Criar grid focado:
noise_levels_refined = [0.0005, 0.001, 0.0015, 0.002, 0.0025]
architectures_refined = ['strongly_entangling', 'hardware_efficient']
init_strategies_refined = ['quantico', 'matematico']

```text

**Benef√≠cio:** Combina efici√™ncia da busca Bayesiana com rigor do grid search.


---


### 6. Early Stopping Inteligente

```python

# Modificar ClassificadorVQC para incluir:
early_stopping_patience = 10  # Parar se n√£o melhorar por 10 √©pocas
early_stopping_delta = 0.001   # Melhoria m√≠nima considerada significativa

def fit(self, X, y, X_val=None, y_val=None):
    best_loss = float('inf')
    patience_counter = 0
    
    for epoca in range(n_epocas):

        # ... treinamento ...
        
        if X_val is not None:
            val_loss = self.compute_loss(X_val, y_val)
            
            if val_loss < best_loss - early_stopping_delta:
                best_loss = val_loss
                patience_counter = 0
            else:
                patience_counter += 1
                
            if patience_counter >= early_stopping_patience:
                logger.info(f"Early stopping na √©poca {epoca}")
                break

```text

**Benef√≠cio:** Economiza tempo de treinamento sem perder qualidade.


---


### 7. Cross-Validation K-Fold

```python
from sklearn.model_selection import KFold

def evaluate_with_cv(config, X, y, n_folds=5):
    """Avalia configura√ß√£o com valida√ß√£o cruzada"""
    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)
    scores = []
    
    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):
        X_train, X_val = X[train_idx], X[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]
        
        vqc = ClassificadorVQC(**config)
        vqc.fit(X_train, y_train)
        score = vqc.score(X_val, y_val)
        scores.append(score)
    
    return np.mean(scores), np.std(scores)

```text

**Benef√≠cio:** Estimativa mais robusta da performance real, reduz overfitting na valida√ß√£o.


---


### 8. Ensemble de Modelos

```python
def ensemble_predict(models, X):
    """Predi√ß√£o por vota√ß√£o majorit√°ria"""
    predictions = np.array([model.predict(X) for model in models])
    
    # Vota√ß√£o majorit√°ria
    from scipy.stats import mode
    ensemble_pred = mode(predictions, axis=0)[0].flatten()
    
    return ensemble_pred

# Treinar m√∫ltiplos modelos com melhores configura√ß√µes
best_configs = study.best_trials[:5]  # Top 5 configura√ß√µes
models = []

for config in best_configs:
    vqc = ClassificadorVQC(**config.params)
    vqc.fit(X_train, y_train)
    models.append(vqc)

# Predi√ß√£o ensemble
y_pred_ensemble = ensemble_predict(models, X_test)
accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)

```text

**Benef√≠cio:** Melhora robustez e pode superar modelos individuais.


---


### 9. An√°lise de Performance Detalhada

#### 9.1. Curvas de Aprendizado

```python
def plot_learning_curves(vqc, X_train, y_train, X_test, y_test):
    """Plota curvas de aprendizado para diagn√≥stico"""
    train_sizes = np.linspace(0.1, 1.0, 10)
    train_scores = []
    test_scores = []
    
    for size in train_sizes:
        n_samples = int(len(X_train) * size)
        X_subset = X_train[:n_samples]
        y_subset = y_train[:n_samples]
        
        vqc_temp = ClassificadorVQC(**vqc.get_params())
        vqc_temp.fit(X_subset, y_subset)
        
        train_scores.append(vqc_temp.score(X_subset, y_subset))
        test_scores.append(vqc_temp.score(X_test, y_test))
    
    plt.figure(figsize=(10, 6))
    plt.plot(train_sizes * len(X_train), train_scores, label='Treino')
    plt.plot(train_sizes * len(X_train), test_scores, label='Teste')
    plt.xlabel('N√∫mero de Amostras de Treino')
    plt.ylabel('Acur√°cia')
    plt.title('Curvas de Aprendizado')
    plt.legend()
    plt.grid(True)
    plt.savefig('learning_curves.png', dpi=300)

```text

#### 9.2. Matriz de Confus√£o Detalhada

```python
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

def detailed_performance_analysis(y_true, y_pred):
    """An√°lise detalhada de performance"""

    # Matriz de confus√£o
    cm = confusion_matrix(y_true, y_pred)
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title('Matriz de Confus√£o')
    plt.ylabel('Verdadeiro')
    plt.xlabel('Predito')
    plt.savefig('confusion_matrix.png', dpi=300)
    
    # Relat√≥rio de classifica√ß√£o
    report = classification_report(y_true, y_pred)
    print(report)
    
    return cm, report

```text

---


### 10. Paraleliza√ß√£o de Trials

```python

# No c√≥digo de otimiza√ß√£o Bayesiana:
study.optimize(
    objective,
    n_trials=200,
    n_jobs=4,  # NOVO: Executar 4 trials em paralelo
    show_progress_bar=True
)

```text

**Benef√≠cio:** Reduz tempo total de execu√ß√£o em 4x (com 4 cores).


**Requisito:** Processador multi-core dispon√≠vel.


---


## üöÄ Recomenda√ß√µes Pr√°ticas

### Para Pesquisa Explorat√≥ria (1-2 horas)

```bash

# Usar Bayesian otimizado com mais trials
export VQC_BAYESIAN=1
export VQC_QUICK=1
python framework_investigativo_completo.py \

    --bayes \
    --trials 500 \
    --dataset-bayes all

```text

### Para M√°xima Performance (4-6 horas)

```bash

# Fase 1: Bayesian (200 trials, 2 horas)
python framework_investigativo_completo.py \

    --bayes \
    --trials 200 \
    --dataset-bayes all


# Fase 2: Grid Search Refinado na regi√£o √≥tima (2-4 horas)
# Ajustar ranges baseado nos resultados da Fase 1
python framework_investigativo_completo.py \

    --grid-focused \
    --focus-region "best_from_phase1"

```text

### Para Publica√ß√£o Cient√≠fica (15-20 horas)

```bash

# Grid Search Completo
python framework_investigativo_completo.py

```text

---


## üìä M√©tricas de Performance Adicionais

### 1. AUC-ROC (Area Under Curve)

```python
from sklearn.metrics import roc_auc_score, roc_curve

# Para classifica√ß√£o bin√°ria
y_proba = vqc.predict_proba(X_test)
auc = roc_auc_score(y_test, y_proba)

```text

### 2. F1-Score (Balanceamento Precision/Recall)

```python
from sklearn.metrics import f1_score

f1 = f1_score(y_test, y_pred, average='weighted')

```text

### 3. Matthews Correlation Coefficient (MCC)

```python
from sklearn.metrics import matthews_corrcoef

mcc = matthews_corrcoef(y_test, y_pred)

```text

---


## üí° Sugest√µes Espec√≠ficas para Este Framework

### 1. Adicionar An√°lise de Sensibilidade

```python
def sensitivity_analysis(base_config, param_name, param_range):
    """Analisa sensibilidade a um hiperpar√¢metro espec√≠fico"""
    results = []
    
    for value in param_range:
        config = base_config.copy()
        config[param_name] = value
        
        vqc = ClassificadorVQC(**config)
        vqc.fit(X_train, y_train)
        score = vqc.score(X_test, y_test)
        
        results.append({'value': value, 'score': score})
    
    return pd.DataFrame(results)

# Exemplo de uso:
noise_sensitivity = sensitivity_analysis(
    base_config=best_config,
    param_name='nivel_ruido',
    param_range=np.linspace(0, 0.02, 20)
)

```text

### 2. Implementar AutoML com AutoGluon

```python

# Alternativa: Usar AutoGluon para busca autom√°tica
from autogluon.tabular import TabularPredictor

# Criar dataset com features extra√≠das do quantum circuit
X_quantum_features = extract_quantum_features(X)

predictor = TabularPredictor(label='target').fit(
    train_data=X_quantum_features,
    time_limit=3600  # 1 hora
)

```text

---


## üìà Benchmarks Esperados

| M√©todo | Trials/Experimentos | Tempo | Acur√°cia Esperada | Uso |
|--------|---------------------|-------|-------------------|-----|
| Quick Bayesian (atual) | 5 | 7 min | 80-82% | Valida√ß√£o r√°pida |
| Bayesian Otimizado | 200 | 1-2h | 85-90% | Pesquisa explorat√≥ria |
| Bayesian Avan√ßado | 500 | 4-6h | 88-92% | M√°xima performance |
| Grid Search Completo | 8,280 | 15-20h | 90-95% | Publica√ß√£o cient√≠fica |
| H√≠brido (2 fases) | 200+50 | 3-4h | 90-93% | Melhor custo-benef√≠cio |

---


## ‚úÖ Checklist de Implementa√ß√£o

Para implementar as melhorias:

- [ ] Aumentar `n_trials` para 200-500
- [ ] Ajustar `n_startup_trials` para 20
- [ ] Implementar ensemble de top-5 modelos
- [ ] Adicionar early stopping inteligente
- [ ] Implementar cross-validation k-fold
- [ ] Adicionar an√°lise de sensibilidade
- [ ] Gerar curvas de aprendizado
- [ ] Calcular m√©tricas adicionais (AUC, F1, MCC)
- [ ] Paralelizar trials (n_jobs=4)
- [ ] Implementar busca em duas fases


---


## üîß Modifica√ß√µes no C√≥digo

### Exemplo: Melhorar Sampler TPE

```python

# No arquivo framework_investigativo_completo.py, linha ~3959:

# ANTES:
sampler = TPESampler(seed=42, n_startup_trials=10)

# DEPOIS:
sampler = TPESampler(
    seed=42,
    n_startup_trials=20,        # Mais explora√ß√£o inicial
    n_ei_candidates=24,         # Mais candidatos para Expected Improvement
    multivariate=True,          # Considerar correla√ß√µes entre hiperpar√¢metros
    warn_independent_sampling=True
)

```text

### Exemplo: Melhorar Pruner

```python

# ANTES:
pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=3)

# DEPOIS:
from optuna.pruners import SuccessiveHalvingPruner

pruner = SuccessiveHalvingPruner(
    min_resource=1,
    reduction_factor=3,
    min_early_stopping_rate=0
)

```

---


## üìö Refer√™ncias

1. **Optuna Documentation:** <https://optuna.readthedocs.io/>
2. **Bergstra et al. (2011):** "Algorithms for Hyper-Parameter Optimization"
3. **Li et al. (2018):** "Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization"
4. **Akiba et al. (2019):** "Optuna: A Next-generation Hyperparameter Optimization Framework"


---


**Conclus√£o:** O framework j√° possui uma base s√≥lida de otimiza√ß√£o Bayesiana. As melhorias sugeridas podem aumentar a acur√°cia em 5-15% e reduzir o tempo de busca em at√© 50%, dependendo da configura√ß√£o escolhida.

